{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4ab16f-a944-406c-8735-7ac5a094850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b3931c-ce35-4d1f-a354-38a3ce7fd48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 26421880/26421880 [00:25<00:00, 1027698.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 29515/29515 [00:00<00:00, 104346.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 4422102/4422102 [00:02<00:00, 1704561.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5148/5148 [00:00<00:00, 739157.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a081fb-2fad-49bc-9a65-426e2b12b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed2f6cd-0170-4667-bd15-f05a9996fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aeac516-2489-4c55-a1b7-61f77154bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a60fd6-9866-478e-a448-a268c23aa5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d052208-4fdb-4a90-97bb-0ded0cc80d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24de138-ef06-420f-809c-39fbebeee469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310186  [   64/60000]\n",
      "loss: 2.288355  [ 6464/60000]\n",
      "loss: 2.266503  [12864/60000]\n",
      "loss: 2.261192  [19264/60000]\n",
      "loss: 2.242662  [25664/60000]\n",
      "loss: 2.212022  [32064/60000]\n",
      "loss: 2.222087  [38464/60000]\n",
      "loss: 2.185393  [44864/60000]\n",
      "loss: 2.182222  [51264/60000]\n",
      "loss: 2.152603  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 2.141449 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.159277  [   64/60000]\n",
      "loss: 2.143014  [ 6464/60000]\n",
      "loss: 2.076170  [12864/60000]\n",
      "loss: 2.096399  [19264/60000]\n",
      "loss: 2.043700  [25664/60000]\n",
      "loss: 1.978481  [32064/60000]\n",
      "loss: 2.010024  [38464/60000]\n",
      "loss: 1.926336  [44864/60000]\n",
      "loss: 1.928695  [51264/60000]\n",
      "loss: 1.860122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 1.851915 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.892306  [   64/60000]\n",
      "loss: 1.858889  [ 6464/60000]\n",
      "loss: 1.730543  [12864/60000]\n",
      "loss: 1.779974  [19264/60000]\n",
      "loss: 1.665390  [25664/60000]\n",
      "loss: 1.619558  [32064/60000]\n",
      "loss: 1.643049  [38464/60000]\n",
      "loss: 1.546448  [44864/60000]\n",
      "loss: 1.571927  [51264/60000]\n",
      "loss: 1.470837  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.483149 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.553310  [   64/60000]\n",
      "loss: 1.524172  [ 6464/60000]\n",
      "loss: 1.367538  [12864/60000]\n",
      "loss: 1.446329  [19264/60000]\n",
      "loss: 1.324092  [25664/60000]\n",
      "loss: 1.321880  [32064/60000]\n",
      "loss: 1.340533  [38464/60000]\n",
      "loss: 1.269619  [44864/60000]\n",
      "loss: 1.301505  [51264/60000]\n",
      "loss: 1.209062  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.228703 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.302587  [   64/60000]\n",
      "loss: 1.296261  [ 6464/60000]\n",
      "loss: 1.126292  [12864/60000]\n",
      "loss: 1.236910  [19264/60000]\n",
      "loss: 1.108230  [25664/60000]\n",
      "loss: 1.131154  [32064/60000]\n",
      "loss: 1.159196  [38464/60000]\n",
      "loss: 1.101369  [44864/60000]\n",
      "loss: 1.133039  [51264/60000]\n",
      "loss: 1.058272  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.073262 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.137559  [   64/60000]\n",
      "loss: 1.154811  [ 6464/60000]\n",
      "loss: 0.969757  [12864/60000]\n",
      "loss: 1.108554  [19264/60000]\n",
      "loss: 0.977582  [25664/60000]\n",
      "loss: 1.004850  [32064/60000]\n",
      "loss: 1.047909  [38464/60000]\n",
      "loss: 0.995324  [44864/60000]\n",
      "loss: 1.022677  [51264/60000]\n",
      "loss: 0.964245  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.973336 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.023437  [   64/60000]\n",
      "loss: 1.063566  [ 6464/60000]\n",
      "loss: 0.862793  [12864/60000]\n",
      "loss: 1.023797  [19264/60000]\n",
      "loss: 0.895195  [25664/60000]\n",
      "loss: 0.915752  [32064/60000]\n",
      "loss: 0.975037  [38464/60000]\n",
      "loss: 0.926127  [44864/60000]\n",
      "loss: 0.945703  [51264/60000]\n",
      "loss: 0.900795  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.904686 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.939258  [   64/60000]\n",
      "loss: 0.999488  [ 6464/60000]\n",
      "loss: 0.785347  [12864/60000]\n",
      "loss: 0.963215  [19264/60000]\n",
      "loss: 0.839009  [25664/60000]\n",
      "loss: 0.849743  [32064/60000]\n",
      "loss: 0.923301  [38464/60000]\n",
      "loss: 0.879062  [44864/60000]\n",
      "loss: 0.889539  [51264/60000]\n",
      "loss: 0.854704  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.854581 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.873945  [   64/60000]\n",
      "loss: 0.950532  [ 6464/60000]\n",
      "loss: 0.726674  [12864/60000]\n",
      "loss: 0.917408  [19264/60000]\n",
      "loss: 0.797998  [25664/60000]\n",
      "loss: 0.799748  [32064/60000]\n",
      "loss: 0.883871  [38464/60000]\n",
      "loss: 0.845652  [44864/60000]\n",
      "loss: 0.847044  [51264/60000]\n",
      "loss: 0.819157  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.816183 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.821638  [   64/60000]\n",
      "loss: 0.910531  [ 6464/60000]\n",
      "loss: 0.680473  [12864/60000]\n",
      "loss: 0.881466  [19264/60000]\n",
      "loss: 0.766147  [25664/60000]\n",
      "loss: 0.761191  [32064/60000]\n",
      "loss: 0.851856  [38464/60000]\n",
      "loss: 0.820516  [44864/60000]\n",
      "loss: 0.813842  [51264/60000]\n",
      "loss: 0.790157  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.785393 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.778137  [   64/60000]\n",
      "loss: 0.876102  [ 6464/60000]\n",
      "loss: 0.642789  [12864/60000]\n",
      "loss: 0.852349  [19264/60000]\n",
      "loss: 0.740246  [25664/60000]\n",
      "loss: 0.730585  [32064/60000]\n",
      "loss: 0.824377  [38464/60000]\n",
      "loss: 0.800510  [44864/60000]\n",
      "loss: 0.787051  [51264/60000]\n",
      "loss: 0.765592  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.759655 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.740987  [   64/60000]\n",
      "loss: 0.845411  [ 6464/60000]\n",
      "loss: 0.611162  [12864/60000]\n",
      "loss: 0.828161  [19264/60000]\n",
      "loss: 0.718309  [25664/60000]\n",
      "loss: 0.705737  [32064/60000]\n",
      "loss: 0.799850  [38464/60000]\n",
      "loss: 0.783811  [44864/60000]\n",
      "loss: 0.764705  [51264/60000]\n",
      "loss: 0.744240  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.737446 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.708788  [   64/60000]\n",
      "loss: 0.817625  [ 6464/60000]\n",
      "loss: 0.584286  [12864/60000]\n",
      "loss: 0.807772  [19264/60000]\n",
      "loss: 0.699269  [25664/60000]\n",
      "loss: 0.685218  [32064/60000]\n",
      "loss: 0.777451  [38464/60000]\n",
      "loss: 0.768911  [44864/60000]\n",
      "loss: 0.745634  [51264/60000]\n",
      "loss: 0.725104  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.717773 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.680381  [   64/60000]\n",
      "loss: 0.792120  [ 6464/60000]\n",
      "loss: 0.560931  [12864/60000]\n",
      "loss: 0.790096  [19264/60000]\n",
      "loss: 0.682539  [25664/60000]\n",
      "loss: 0.667821  [32064/60000]\n",
      "loss: 0.756542  [38464/60000]\n",
      "loss: 0.755422  [44864/60000]\n",
      "loss: 0.728995  [51264/60000]\n",
      "loss: 0.707593  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.700036 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.655030  [   64/60000]\n",
      "loss: 0.768612  [ 6464/60000]\n",
      "loss: 0.540358  [12864/60000]\n",
      "loss: 0.774561  [19264/60000]\n",
      "loss: 0.667635  [25664/60000]\n",
      "loss: 0.652899  [32064/60000]\n",
      "loss: 0.736894  [38464/60000]\n",
      "loss: 0.743123  [44864/60000]\n",
      "loss: 0.714404  [51264/60000]\n",
      "loss: 0.691383  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.683849 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.632281  [   64/60000]\n",
      "loss: 0.746828  [ 6464/60000]\n",
      "loss: 0.522078  [12864/60000]\n",
      "loss: 0.760536  [19264/60000]\n",
      "loss: 0.654466  [25664/60000]\n",
      "loss: 0.639929  [32064/60000]\n",
      "loss: 0.718441  [38464/60000]\n",
      "loss: 0.731920  [44864/60000]\n",
      "loss: 0.701657  [51264/60000]\n",
      "loss: 0.676362  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.668989 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.611784  [   64/60000]\n",
      "loss: 0.726741  [ 6464/60000]\n",
      "loss: 0.505656  [12864/60000]\n",
      "loss: 0.747828  [19264/60000]\n",
      "loss: 0.642694  [25664/60000]\n",
      "loss: 0.628567  [32064/60000]\n",
      "loss: 0.701139  [38464/60000]\n",
      "loss: 0.721806  [44864/60000]\n",
      "loss: 0.690531  [51264/60000]\n",
      "loss: 0.662405  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.655333 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.593200  [   64/60000]\n",
      "loss: 0.708352  [ 6464/60000]\n",
      "loss: 0.490872  [12864/60000]\n",
      "loss: 0.736214  [19264/60000]\n",
      "loss: 0.632190  [25664/60000]\n",
      "loss: 0.618555  [32064/60000]\n",
      "loss: 0.684889  [38464/60000]\n",
      "loss: 0.712758  [44864/60000]\n",
      "loss: 0.680859  [51264/60000]\n",
      "loss: 0.649431  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.642770 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.576274  [   64/60000]\n",
      "loss: 0.691481  [ 6464/60000]\n",
      "loss: 0.477520  [12864/60000]\n",
      "loss: 0.725510  [19264/60000]\n",
      "loss: 0.622694  [25664/60000]\n",
      "loss: 0.609828  [32064/60000]\n",
      "loss: 0.669592  [38464/60000]\n",
      "loss: 0.704677  [44864/60000]\n",
      "loss: 0.672474  [51264/60000]\n",
      "loss: 0.637346  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.631199 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.560654  [   64/60000]\n",
      "loss: 0.675899  [ 6464/60000]\n",
      "loss: 0.465395  [12864/60000]\n",
      "loss: 0.715609  [19264/60000]\n",
      "loss: 0.614027  [25664/60000]\n",
      "loss: 0.601943  [32064/60000]\n",
      "loss: 0.655244  [38464/60000]\n",
      "loss: 0.697499  [44864/60000]\n",
      "loss: 0.665228  [51264/60000]\n",
      "loss: 0.625966  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.620525 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.546289  [   64/60000]\n",
      "loss: 0.661533  [ 6464/60000]\n",
      "loss: 0.454354  [12864/60000]\n",
      "loss: 0.706397  [19264/60000]\n",
      "loss: 0.606153  [25664/60000]\n",
      "loss: 0.594911  [32064/60000]\n",
      "loss: 0.641798  [38464/60000]\n",
      "loss: 0.691366  [44864/60000]\n",
      "loss: 0.659084  [51264/60000]\n",
      "loss: 0.615193  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.610675 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.533111  [   64/60000]\n",
      "loss: 0.648275  [ 6464/60000]\n",
      "loss: 0.444288  [12864/60000]\n",
      "loss: 0.697915  [19264/60000]\n",
      "loss: 0.598802  [25664/60000]\n",
      "loss: 0.588571  [32064/60000]\n",
      "loss: 0.629246  [38464/60000]\n",
      "loss: 0.686154  [44864/60000]\n",
      "loss: 0.653737  [51264/60000]\n",
      "loss: 0.605019  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.601567 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.521008  [   64/60000]\n",
      "loss: 0.636083  [ 6464/60000]\n",
      "loss: 0.434984  [12864/60000]\n",
      "loss: 0.689899  [19264/60000]\n",
      "loss: 0.591874  [25664/60000]\n",
      "loss: 0.582694  [32064/60000]\n",
      "loss: 0.617483  [38464/60000]\n",
      "loss: 0.681729  [44864/60000]\n",
      "loss: 0.649197  [51264/60000]\n",
      "loss: 0.595315  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.593166 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.509771  [   64/60000]\n",
      "loss: 0.624803  [ 6464/60000]\n",
      "loss: 0.426355  [12864/60000]\n",
      "loss: 0.682381  [19264/60000]\n",
      "loss: 0.585241  [25664/60000]\n",
      "loss: 0.577342  [32064/60000]\n",
      "loss: 0.606570  [38464/60000]\n",
      "loss: 0.678144  [44864/60000]\n",
      "loss: 0.645309  [51264/60000]\n",
      "loss: 0.585978  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.585391 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.499251  [   64/60000]\n",
      "loss: 0.614332  [ 6464/60000]\n",
      "loss: 0.418411  [12864/60000]\n",
      "loss: 0.675314  [19264/60000]\n",
      "loss: 0.578748  [25664/60000]\n",
      "loss: 0.572302  [32064/60000]\n",
      "loss: 0.596477  [38464/60000]\n",
      "loss: 0.675259  [44864/60000]\n",
      "loss: 0.641934  [51264/60000]\n",
      "loss: 0.577063  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.578177 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.489345  [   64/60000]\n",
      "loss: 0.604595  [ 6464/60000]\n",
      "loss: 0.410971  [12864/60000]\n",
      "loss: 0.668585  [19264/60000]\n",
      "loss: 0.572392  [25664/60000]\n",
      "loss: 0.567470  [32064/60000]\n",
      "loss: 0.587091  [38464/60000]\n",
      "loss: 0.672953  [44864/60000]\n",
      "loss: 0.638986  [51264/60000]\n",
      "loss: 0.568502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.571473 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.479928  [   64/60000]\n",
      "loss: 0.595577  [ 6464/60000]\n",
      "loss: 0.403969  [12864/60000]\n",
      "loss: 0.662156  [19264/60000]\n",
      "loss: 0.566193  [25664/60000]\n",
      "loss: 0.562756  [32064/60000]\n",
      "loss: 0.578384  [38464/60000]\n",
      "loss: 0.671213  [44864/60000]\n",
      "loss: 0.636446  [51264/60000]\n",
      "loss: 0.560260  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.565227 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.471014  [   64/60000]\n",
      "loss: 0.587164  [ 6464/60000]\n",
      "loss: 0.397423  [12864/60000]\n",
      "loss: 0.655967  [19264/60000]\n",
      "loss: 0.560090  [25664/60000]\n",
      "loss: 0.558114  [32064/60000]\n",
      "loss: 0.570320  [38464/60000]\n",
      "loss: 0.669914  [44864/60000]\n",
      "loss: 0.634143  [51264/60000]\n",
      "loss: 0.552261  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.559387 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.462569  [   64/60000]\n",
      "loss: 0.579332  [ 6464/60000]\n",
      "loss: 0.391246  [12864/60000]\n",
      "loss: 0.650024  [19264/60000]\n",
      "loss: 0.554026  [25664/60000]\n",
      "loss: 0.553553  [32064/60000]\n",
      "loss: 0.562817  [38464/60000]\n",
      "loss: 0.669000  [44864/60000]\n",
      "loss: 0.632059  [51264/60000]\n",
      "loss: 0.544482  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.553917 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.454515  [   64/60000]\n",
      "loss: 0.572012  [ 6464/60000]\n",
      "loss: 0.385386  [12864/60000]\n",
      "loss: 0.644289  [19264/60000]\n",
      "loss: 0.547981  [25664/60000]\n",
      "loss: 0.549012  [32064/60000]\n",
      "loss: 0.555790  [38464/60000]\n",
      "loss: 0.668453  [44864/60000]\n",
      "loss: 0.630216  [51264/60000]\n",
      "loss: 0.536988  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.548789 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.446780  [   64/60000]\n",
      "loss: 0.565136  [ 6464/60000]\n",
      "loss: 0.379821  [12864/60000]\n",
      "loss: 0.638713  [19264/60000]\n",
      "loss: 0.541992  [25664/60000]\n",
      "loss: 0.544584  [32064/60000]\n",
      "loss: 0.549186  [38464/60000]\n",
      "loss: 0.668094  [44864/60000]\n",
      "loss: 0.628514  [51264/60000]\n",
      "loss: 0.529701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.543975 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.439380  [   64/60000]\n",
      "loss: 0.558740  [ 6464/60000]\n",
      "loss: 0.374649  [12864/60000]\n",
      "loss: 0.633304  [19264/60000]\n",
      "loss: 0.536098  [25664/60000]\n",
      "loss: 0.540140  [32064/60000]\n",
      "loss: 0.542944  [38464/60000]\n",
      "loss: 0.667950  [44864/60000]\n",
      "loss: 0.626757  [51264/60000]\n",
      "loss: 0.522660  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.539456 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.432426  [   64/60000]\n",
      "loss: 0.552666  [ 6464/60000]\n",
      "loss: 0.369722  [12864/60000]\n",
      "loss: 0.628107  [19264/60000]\n",
      "loss: 0.530330  [25664/60000]\n",
      "loss: 0.535685  [32064/60000]\n",
      "loss: 0.537207  [38464/60000]\n",
      "loss: 0.668001  [44864/60000]\n",
      "loss: 0.625126  [51264/60000]\n",
      "loss: 0.515869  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.535204 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.425721  [   64/60000]\n",
      "loss: 0.546966  [ 6464/60000]\n",
      "loss: 0.365094  [12864/60000]\n",
      "loss: 0.623114  [19264/60000]\n",
      "loss: 0.524602  [25664/60000]\n",
      "loss: 0.531249  [32064/60000]\n",
      "loss: 0.531881  [38464/60000]\n",
      "loss: 0.668172  [44864/60000]\n",
      "loss: 0.623643  [51264/60000]\n",
      "loss: 0.509413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.531206 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.419211  [   64/60000]\n",
      "loss: 0.541651  [ 6464/60000]\n",
      "loss: 0.360699  [12864/60000]\n",
      "loss: 0.618340  [19264/60000]\n",
      "loss: 0.519015  [25664/60000]\n",
      "loss: 0.526847  [32064/60000]\n",
      "loss: 0.526911  [38464/60000]\n",
      "loss: 0.668427  [44864/60000]\n",
      "loss: 0.622151  [51264/60000]\n",
      "loss: 0.503212  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.527441 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.413062  [   64/60000]\n",
      "loss: 0.536685  [ 6464/60000]\n",
      "loss: 0.356513  [12864/60000]\n",
      "loss: 0.613741  [19264/60000]\n",
      "loss: 0.513530  [25664/60000]\n",
      "loss: 0.522462  [32064/60000]\n",
      "loss: 0.522211  [38464/60000]\n",
      "loss: 0.668683  [44864/60000]\n",
      "loss: 0.620648  [51264/60000]\n",
      "loss: 0.497306  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.523889 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.407160  [   64/60000]\n",
      "loss: 0.532010  [ 6464/60000]\n",
      "loss: 0.352496  [12864/60000]\n",
      "loss: 0.609281  [19264/60000]\n",
      "loss: 0.508213  [25664/60000]\n",
      "loss: 0.518127  [32064/60000]\n",
      "loss: 0.517827  [38464/60000]\n",
      "loss: 0.668928  [44864/60000]\n",
      "loss: 0.619184  [51264/60000]\n",
      "loss: 0.491685  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.520536 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.401533  [   64/60000]\n",
      "loss: 0.527582  [ 6464/60000]\n",
      "loss: 0.348673  [12864/60000]\n",
      "loss: 0.604923  [19264/60000]\n",
      "loss: 0.503087  [25664/60000]\n",
      "loss: 0.513847  [32064/60000]\n",
      "loss: 0.513719  [38464/60000]\n",
      "loss: 0.669105  [44864/60000]\n",
      "loss: 0.617702  [51264/60000]\n",
      "loss: 0.486322  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.517363 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.396124  [   64/60000]\n",
      "loss: 0.523376  [ 6464/60000]\n",
      "loss: 0.345030  [12864/60000]\n",
      "loss: 0.600712  [19264/60000]\n",
      "loss: 0.498098  [25664/60000]\n",
      "loss: 0.509621  [32064/60000]\n",
      "loss: 0.509856  [38464/60000]\n",
      "loss: 0.669229  [44864/60000]\n",
      "loss: 0.616210  [51264/60000]\n",
      "loss: 0.481161  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.514356 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.390914  [   64/60000]\n",
      "loss: 0.519455  [ 6464/60000]\n",
      "loss: 0.341548  [12864/60000]\n",
      "loss: 0.596649  [19264/60000]\n",
      "loss: 0.493267  [25664/60000]\n",
      "loss: 0.505557  [32064/60000]\n",
      "loss: 0.506248  [38464/60000]\n",
      "loss: 0.669221  [44864/60000]\n",
      "loss: 0.614640  [51264/60000]\n",
      "loss: 0.476252  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.511503 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.385935  [   64/60000]\n",
      "loss: 0.515737  [ 6464/60000]\n",
      "loss: 0.338206  [12864/60000]\n",
      "loss: 0.592708  [19264/60000]\n",
      "loss: 0.488582  [25664/60000]\n",
      "loss: 0.501556  [32064/60000]\n",
      "loss: 0.502837  [38464/60000]\n",
      "loss: 0.669119  [44864/60000]\n",
      "loss: 0.613097  [51264/60000]\n",
      "loss: 0.471615  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.508792 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.381152  [   64/60000]\n",
      "loss: 0.512219  [ 6464/60000]\n",
      "loss: 0.335015  [12864/60000]\n",
      "loss: 0.588898  [19264/60000]\n",
      "loss: 0.484007  [25664/60000]\n",
      "loss: 0.497704  [32064/60000]\n",
      "loss: 0.499648  [38464/60000]\n",
      "loss: 0.668878  [44864/60000]\n",
      "loss: 0.611579  [51264/60000]\n",
      "loss: 0.467247  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.506215 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.376549  [   64/60000]\n",
      "loss: 0.508841  [ 6464/60000]\n",
      "loss: 0.331982  [12864/60000]\n",
      "loss: 0.585221  [19264/60000]\n",
      "loss: 0.479618  [25664/60000]\n",
      "loss: 0.493963  [32064/60000]\n",
      "loss: 0.496574  [38464/60000]\n",
      "loss: 0.668525  [44864/60000]\n",
      "loss: 0.610020  [51264/60000]\n",
      "loss: 0.463097  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.503754 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.372160  [   64/60000]\n",
      "loss: 0.505635  [ 6464/60000]\n",
      "loss: 0.329065  [12864/60000]\n",
      "loss: 0.581614  [19264/60000]\n",
      "loss: 0.475326  [25664/60000]\n",
      "loss: 0.490304  [32064/60000]\n",
      "loss: 0.493659  [38464/60000]\n",
      "loss: 0.668009  [44864/60000]\n",
      "loss: 0.608416  [51264/60000]\n",
      "loss: 0.459147  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.501406 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.367929  [   64/60000]\n",
      "loss: 0.502614  [ 6464/60000]\n",
      "loss: 0.326274  [12864/60000]\n",
      "loss: 0.578106  [19264/60000]\n",
      "loss: 0.471123  [25664/60000]\n",
      "loss: 0.486829  [32064/60000]\n",
      "loss: 0.490873  [38464/60000]\n",
      "loss: 0.667368  [44864/60000]\n",
      "loss: 0.606814  [51264/60000]\n",
      "loss: 0.455410  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499162 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.363809  [   64/60000]\n",
      "loss: 0.499808  [ 6464/60000]\n",
      "loss: 0.323601  [12864/60000]\n",
      "loss: 0.574579  [19264/60000]\n",
      "loss: 0.466985  [25664/60000]\n",
      "loss: 0.483556  [32064/60000]\n",
      "loss: 0.488034  [38464/60000]\n",
      "loss: 0.666555  [44864/60000]\n",
      "loss: 0.605184  [51264/60000]\n",
      "loss: 0.451851  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497008 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.359714  [   64/60000]\n",
      "loss: 0.497171  [ 6464/60000]\n",
      "loss: 0.321047  [12864/60000]\n",
      "loss: 0.571203  [19264/60000]\n",
      "loss: 0.463142  [25664/60000]\n",
      "loss: 0.480339  [32064/60000]\n",
      "loss: 0.485365  [38464/60000]\n",
      "loss: 0.665643  [44864/60000]\n",
      "loss: 0.603504  [51264/60000]\n",
      "loss: 0.448499  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.494941 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.355731  [   64/60000]\n",
      "loss: 0.494626  [ 6464/60000]\n",
      "loss: 0.318640  [12864/60000]\n",
      "loss: 0.568048  [19264/60000]\n",
      "loss: 0.459418  [25664/60000]\n",
      "loss: 0.477246  [32064/60000]\n",
      "loss: 0.482825  [38464/60000]\n",
      "loss: 0.664670  [44864/60000]\n",
      "loss: 0.601949  [51264/60000]\n",
      "loss: 0.445375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.492958 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.351869  [   64/60000]\n",
      "loss: 0.492168  [ 6464/60000]\n",
      "loss: 0.316289  [12864/60000]\n",
      "loss: 0.565025  [19264/60000]\n",
      "loss: 0.455838  [25664/60000]\n",
      "loss: 0.474287  [32064/60000]\n",
      "loss: 0.480411  [38464/60000]\n",
      "loss: 0.663674  [44864/60000]\n",
      "loss: 0.600424  [51264/60000]\n",
      "loss: 0.442426  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.491057 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.348164  [   64/60000]\n",
      "loss: 0.489763  [ 6464/60000]\n",
      "loss: 0.314033  [12864/60000]\n",
      "loss: 0.562136  [19264/60000]\n",
      "loss: 0.452338  [25664/60000]\n",
      "loss: 0.471459  [32064/60000]\n",
      "loss: 0.478006  [38464/60000]\n",
      "loss: 0.662592  [44864/60000]\n",
      "loss: 0.598880  [51264/60000]\n",
      "loss: 0.439639  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.489225 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f73641-40c6-46d5-b15f-db96b7a919df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fec5f58-aefe-46b1-b6d4-04ba7ebc3011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3836a2d-1cf2-485d-b111-29d50c1f6299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16373bc-4d58-4cec-9e29-8851df5ecfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
